{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install ultralytics\n",
    "\n",
    "pip install xmltodict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. conda create --prefix \"C:\\\\Users\\\\rs659\\\\Desktop\\\\Object-Detection\\\\wincondaprojenv\" python=3.11.6  \n",
    "2. conda activate \"C:\\\\Users\\\\rs659\\\\Desktop\\\\Object-Detection\\\\wincondaprojenv\"\n",
    "3. pip install torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 --index-url https://download.pytorch.org/whl/cu118\n",
    "4. conda install -p c:\\Users\\rs659\\Desktop\\Object-Detection\\wincondaprojenv ipykernel --update-deps --force-reinstall\n",
    "\n",
    "\n",
    "pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu121\n",
    "conda install -p c:\\Users\\rs659\\Desktop\\Object-Detection\\wincondaprojenv ipykernel --update-deps --force-reinstall\n",
    "\n",
    "5. pip install pybind11\n",
    "6. pip install opencv-python\n",
    "7. pip instal ultralytics\n",
    "8. pip install pylabel\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Merge Different COCO dataset\n",
    "https://gradiant.github.io/pyodi/reference/apps/coco-merge/\n",
    "pyodi coco merge coco_1.json coco_2.json output.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from pylabel import importer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  'DatasetDetectron2\\\\annotations\\\\MergeDataset\\\\train\\\\05993C52-D3D7-4847-8CB3-8AC92F9586EF_1_105_c.jpeg'\n",
    "\n",
    "### FOR TRAIN ###\n",
    "#Specify path to the coco.json file\n",
    "path_to_annotations = \"DatasetDetectron2/annotations/train.json\"\n",
    "#Specify the path to the images (if they are in a different folder than the annotations)\n",
    "path_to_images = os.getcwd() + \"/MergeDataset/train/\"\n",
    "\n",
    "#Import the dataset into the pylable schema\n",
    "dataset = importer.ImportCoco(path_to_annotations, path_to_images=path_to_images, name=\"BCCD_coco\")\n",
    "dataset.df.head(5)\n",
    "\n",
    "dataset.splitter.GroupShuffleSplit(train_pct=.6, val_pct=.2, test_pct=.2)\n",
    "dataset.analyze.ShowClassSplits()\n",
    "# dataset.export.ExportToYoloV5(output_path='YOLO_dataset/train/labels',yaml_file='YOLO_dataset/train/dataset.yaml', copy_images=True, use_splits=True)\n",
    "\n",
    "dataset.export.ExportToYoloV5(output_path='YOLO_dataset_train/labels',yaml_file='dataset.yaml', copy_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOR TEST ###\n",
    "\n",
    "# #Specify path to the coco.json file\n",
    "path_to_annotations = \"DatasetDetectron2/annotations/test.json\"\n",
    "#Specify the path to the images (if they are in a different folder than the annotations)\n",
    "path_to_images = os.getcwd() + \"/MergeDataset/train/\"\n",
    "\n",
    "#Import the dataset into the pylable schema\n",
    "dataset = importer.ImportCoco(path_to_annotations, path_to_images=path_to_images, name=\"BCCD_coco\")\n",
    "dataset.df.head(5)\n",
    "\n",
    "dataset.splitter.GroupShuffleSplit(train_pct=.6, val_pct=.2, test_pct=.2)\n",
    "dataset.analyze.ShowClassSplits()\n",
    "# dataset.export.ExportToYoloV5(output_path='YOLO_dataset/train/labels',yaml_file='YOLO_dataset/train/dataset.yaml', copy_images=True, use_splits=True)\n",
    "\n",
    "dataset.export.ExportToYoloV5(output_path='YOLO_dataset_test/labels',yaml_file='dataset.yaml', copy_images=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create the main directory\n",
    "os.makedirs('YOLO_dataset', exist_ok=True)\n",
    "\n",
    "# # Create subdirectories for labels and images\n",
    "# os.makedirs('YOLO_dataset/labels/train', exist_ok=True)\n",
    "# os.makedirs('YOLO_dataset/labels/test', exist_ok=True)\n",
    "# os.makedirs('YOLO_dataset/images/train', exist_ok=True)\n",
    "# os.makedirs('YOLO_dataset/images/test', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cp YOLO_dataset_test/images YOLO_dataset\\images\\train\n",
    "# !cp YOLO_dataset_train/images YOLO_dataset\\images\\test\n",
    "\n",
    "import shutil\n",
    "\n",
    "# Copy images from YOLO_dataset_test/images to YOLO_dataset/images/train\n",
    "shutil.copytree('YOLO_dataset_test/images', 'YOLO_dataset/images/train')\n",
    "\n",
    "# Copy images from YOLO_dataset_train/images to YOLO_dataset/images/test\n",
    "shutil.copytree('YOLO_dataset_train/images', 'YOLO_dataset/images/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !copy YOLO_dataset_test/labels YOLO_dataset\\labels\n",
    "# !copy YOLO_dataset_train/labels YOLO_dataset\\labels\n",
    "\n",
    "# shutil.copytree('YOLO_dataset_test/labels', 'YOLO_dataset/labels')\n",
    "\n",
    "# shutil.copytree('YOLO_dataset_train/labels', 'YOLO_dataset/labels/')\n",
    "\n",
    "# Define source and destination directories\n",
    "# source_dirs = ['YOLO_dataset_test/labels', 'YOLO_dataset_train/labels']\n",
    "# destination_dir = 'YOLO_dataset/labels'\n",
    "\n",
    "# # Copy contents of the first directory\n",
    "# for source_dir in source_dirs:\n",
    "#     for root, dirs, files in os.walk(source_dir):\n",
    "#         for file in files:\n",
    "#             source_file = os.path.join(root, file)\n",
    "#             relative_path = os.path.relpath(source_file, source_dir)\n",
    "#             destination_file = os.path.join(destination_dir, relative_path)\n",
    "#             os.makedirs(os.path.dirname(destination_file), exist_ok=True)\n",
    "#             shutil.copy(source_file, destination_file)\n",
    "\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Define source and destination paths\n",
    "test_source = 'YOLO_dataset_test/labels'\n",
    "train_source = 'YOLO_dataset_train/labels'\n",
    "test_dest = 'YOLO_dataset/labels/test'\n",
    "train_dest = 'YOLO_dataset/labels/train'\n",
    "\n",
    "# # Ensure destination directories exist\n",
    "# os.makedirs(test_dest, exist_ok=True)\n",
    "# os.makedirs(train_dest, exist_ok=True)\n",
    "\n",
    "# Copy directories\n",
    "try:\n",
    "    shutil.copytree(test_source, test_dest)\n",
    "    shutil.copytree(train_source, train_dest)\n",
    "    print(\"Directories copied successfully!\")\n",
    "except FileExistsError:\n",
    "    print(\"Destination directories already exist. Remove or rename them and try again.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !copy DatasetDetectron2\\annotations\\dataset.yaml YOLO_dataset\\\n",
    "\n",
    "source_file = \"DatasetDetectron2/annotations/dataset.yaml\"\n",
    "destination_dir = \"YOLO_dataset\"\n",
    "\n",
    "shutil.copy(source_file, destination_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/pylabel-project/samples/blob/main/coco2yolov5.ipynb\n",
    "# dataset.path_to_annotations = \"data/yolo\"\n",
    "# dataset.export.ExportToYoloV5()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "# ROOT_DIR = 'C:\\\\Users\\\\rs659\\\\Desktop\\\\Object-Detection\\\\YOLO_dataset'\n",
    "# ROOT_DIR = 'C:\\\\Users\\\\rs659\\\\Desktop\\\\Object-Detection//trainingsplit//'\n",
    "ROOT_DIR = '/Users/rishabhshah/Desktop/AIPI590/Object-Detection/YOLO_dataset'\n",
    "\n",
    "\n",
    "# Load a model\n",
    "# model = YOLO(\"yolov8n.yaml\")  # build a new model from scratch\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "\n",
    "# Use the model\n",
    "results = model.train(data=os.path.join(ROOT_DIR, \"dataset.yaml\"), epochs=1)  # train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# ROOT_DIR = 'C:\\\\Users\\\\rs659\\\\Desktop\\\\Object-Detection\\\\YOLO_dataset\\\\'\n",
    "ROOT_DIR = 'C:\\\\Users\\\\rs659\\\\Desktop\\\\Object-Detection//trainingsplit//'\n",
    "# ROOT_DIR = '/Users/rishabhshah/Desktop/AIPI590/Project2/training'\n",
    "\n",
    "\n",
    "# Load a model\n",
    "# model = YOLO(\"yolov8n.yaml\")  # build a new model from scratch\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Use the model\n",
    "results = model.train(data=os.path.join(ROOT_DIR, \"dataset.yaml\"), epochs=2, save_dir='models/YOLO')  # train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
